system:
  name: "sundaygraph"
  version: "1.0.0"
  log_level: "INFO"
  log_file: "logs/sundaygraph.log"

data:
  input_dir: "./data/input"
  output_dir: "./data/output"
  cache_dir: "./data/cache"
  supported_formats:
    - json
    - csv
    - txt
    - xml
    - pdf
    - docx
  max_file_size_mb: 100

ontology:
  schema_path: "./config/ontology_schema.yaml"  # Initial/fallback schema
  auto_validate: true
  strict_mode: false
  allow_custom_properties: true
  build_with_llm: true  # Build schema using LLM reasoning
  store_in_postgres: true  # Store schema metadata in PostgreSQL
  evolve_automatically: true  # Evolve schema based on data

graph:
  backend: "memory"  # Lightweight graph for data hydration (LightRAG-inspired)
  memory:
    directed: true
    multigraph: false
  neo4j:
    uri: "bolt://neo4j:7687"  # Use service name in Docker
    user: "neo4j"
    password: "password"
    database: "neo4j"
    max_connection_lifetime: 3600
    max_connection_pool_size: 50

# PostgreSQL for schema metadata storage (OntoCast-inspired)
schema_store:
  enabled: true
  # Use service name in Docker, localhost for local
  host: "localhost"  # Change to "postgres" for Docker
  port: 5432
  database: "sundaygraph"
  user: "postgres"
  password: "password"

agents:
  data_ingestion:
    enabled: true
    batch_size: 100
    max_workers: 4
    chunk_size: 1000
    overlap: 200
    extract_entities: true
    extract_relations: true
    
  ontology:
    enabled: true
    strict_mode: false
    auto_map_properties: true
    validation_level: "medium"  # Options: "strict", "medium", "loose"
    use_llm_reasoning: true  # Use LLM for intelligent reasoning
    
  graph_construction:
    enabled: true
    batch_insert_size: 1000
    create_indexes: true
    deduplicate_entities: true
    merge_relations: true
    
  query:
    enabled: true
    max_results: 100
    similarity_threshold: 0.7
    use_semantic_search: true

processing:
  nlp:
    model: "en_core_web_sm"
    use_gpu: false
    batch_size: 32
    
  embedding:
    model: "sentence-transformers/all-MiniLM-L6-v2"
    dimension: 384
    device: "cpu"
    
  llm:
    provider: "openai"  # Using OpenAI for all reasoning
    model: "gpt-4"
    temperature: 0.7
    max_tokens: 2000
    api_key: "${OPENAI_API_KEY}"  # From environment variable

storage:
  persist_graph: true
  graph_file: "./data/graph.pkl"
  backup_enabled: true
  backup_interval_hours: 24
